{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Exercise 4: Embedded Development Environment & Implementation Guide\n\n## üéØ Learning Objectives\nBy the end of this exercise, you will be able to:\n- Set up and use the STM32CubeIDE development environment\n- Build and debug embedded AI applications\n- Understand the core image processing functions for face recognition\n- Implement and test face recognition algorithms step by step\n- Validate implementations with real-time camera data\n\n## üìã Prerequisites\n- Completed Exercises 1-3 (Pipeline understanding, model conversion, flashing)\n- STM32CubeIDE installed on your system\n- STM32N6 development board connected\n- Basic understanding of C programming"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Part 1: Development Environment Setup\n",
    "\n",
    "### Step 1: Opening the Project in STM32CubeIDE\n",
    "\n",
    "1. **Launch STM32CubeIDE**\n",
    "   - Open STM32CubeIDE from your applications menu\n",
    "   - Select or create a workspace directory\n",
    "\n",
    "2. **Import the Project**\n",
    "   ```\n",
    "   File ‚Üí Import ‚Üí General ‚Üí Existing Projects into Workspace\n",
    "   ‚Üí Browse to: /home/vboxuser/Desktop/Workshop/EdgeAI_Workshop\n",
    "   ‚Üí Select \"EdgeAI_Workshop\" project\n",
    "   ‚Üí Click \"Finish\"\n",
    "   ```\n",
    "\n",
    "3. **Project Structure Overview**\n",
    "   ```\n",
    "   EdgeAI_Workshop/\n",
    "   ‚îú‚îÄ‚îÄ STM32CubeIDE/           # IDE project files\n",
    "   ‚îú‚îÄ‚îÄ Src/                    # Source code (.c files)\n",
    "   ‚îú‚îÄ‚îÄ Inc/                    # Header files (.h files)\n",
    "   ‚îú‚îÄ‚îÄ Middlewares/            # ST middleware libraries\n",
    "   ‚îú‚îÄ‚îÄ STM32Cube_FW_N6/       # STM32 HAL drivers\n",
    "   ‚îú‚îÄ‚îÄ Makefile               # Command-line build system\n",
    "   ‚îî‚îÄ‚îÄ dummy_buffer/          # Test data and utilities\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Verifying Build System\n",
    "\n",
    "#### Using STM32CubeIDE \n",
    "\n",
    "1. **Clean and Build**\n",
    "   ```\n",
    "   Project ‚Üí Clean... ‚Üí Select \"EdgeAI_Workshop\" ‚Üí Clean\n",
    "   Project ‚Üí Build Project (or Ctrl+B)\n",
    "   ```\n",
    "\n",
    "2. **Expected Output**\n",
    "   - Build should complete without errors\n",
    "   - Look for: `Finished building target: STM32N6_GettingStarted_ObjectDetection.elf`\n",
    "   - Binary files should be generated in `STM32CubeIDE/Debug/`\n",
    "\n",
    "   ```\n",
    "\n",
    "### ‚ö†Ô∏è Troubleshooting Build Issues\n",
    "\n",
    "**Common Problems:**\n",
    "- **Missing ARM toolchain**: Install `arm-none-eabi-gcc`\n",
    "- **Path issues**: Ensure STM32CubeIDE can find the toolchain\n",
    "- **Permission errors**: Check file permissions in project directory\n",
    "- **Memory issues**: Close other applications if build fails due to memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Debug Mode Setup and Testing\n",
    "\n",
    "#### Hardware Connection Verification\n",
    "\n",
    "1. **Check ST-Link Connection**\n",
    "   - Connect STM32N6 board via USB\n",
    "   - Verify green LED on ST-Link portion\n",
    "   - In terminal: `lsusb | grep STMicroelectronics`\n",
    "\n",
    "   ```\n",
    "\n",
    "#### Testing Debug Session\n",
    "\n",
    "1. **Start Debug Session**\n",
    "   ```\n",
    "   Click \"Debug\" ‚Üí Switch to Debug perspective ‚Üí Yes\n",
    "   ```\n",
    "\n",
    "2. **Verify Debug Functionality**\n",
    "   - Program should halt at `main()` function\n",
    "   - Set breakpoint at line with `printf(\"üöÄ Starting Edge AI Workshop...\")`\n",
    "   - Press F8 (Resume) and verify it hits the breakpoint\n",
    "   - Check Variables view shows local variables\n",
    "   - Verify SWV ITM Console shows printf output\n",
    "\n",
    "\n",
    "### ‚ö†Ô∏è Troubleshooting Debug Issues\n",
    "\n",
    "**Common Problems:**\n",
    "- **\"No ST-Link detected\"**: Check USB connection, try different port\n",
    "- **\"Target not responding\"**: Power cycle the board, check jumper settings\n",
    "- **Breakpoints not hit**: Ensure debug symbols are included in build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ‚öôÔ∏è Part 2: Application Architecture Deep Dive\n\n### Understanding the Face Recognition Pipeline\n\nThis project implements a complete face detection and recognition pipeline with the following components:\n\n### üìç Core Application Flow\n\n**Location**: Main processing loop in `main.c`\n\n```c\n/* ========================================================================= */\n/* MAIN PROCESSING PIPELINE                                                  */\n/* ========================================================================= */\n/* Complete face detection and recognition implementation                    */\n/* ========================================================================= */\n\nwhile (1) {\n    // 1. Camera input capture\n    capture_camera_frame();\n    \n    // 2. Face detection preprocessing\n    prepare_centerface_input();\n    \n    // 3. CenterFace inference\n    run_face_detection();\n    \n    // 4. Face postprocessing & cropping\n    extract_and_align_faces();\n    \n    // 5. MobileFaceNet inference\n    generate_face_embeddings();\n    \n    // 6. Face recognition & similarity\n    calculate_face_similarity();\n    \n    // 7. Display results\n    display_recognition_results();\n}\n```\n\n#### üéØ Key Pipeline Stages:\n1. **Camera Input** ‚Üí Real-time image capture from camera module\n2. **Face Detection** ‚Üí CenterFace TFLite model for face localization\n3. **Face Alignment** ‚Üí Crop and normalize detected faces\n4. **Feature Extraction** ‚Üí MobileFaceNet for embedding generation\n5. **Recognition** ‚Üí Cosine similarity for face matching\n6. **Display Output** ‚Üí Visual feedback on LCD display"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### üìç Input Data Management\n\n**Location**: `Inc/app_config.h` and `Src/dummy_buffer.c`\n\nThe application supports flexible input data management for testing and development:\n\n#### üéØ Test Data System\n\n1. **Camera Input Mode**:\n   ```c\n   // Live camera stream processing\n   capture_camera_frame(&img_buffer);\n   process_frame_for_detection();\n   ```\n\n2. **Test Data Mode**:\n   ```c\n   // Pre-loaded test images for consistent validation\n   load_test_image_buffer();\n   validate_against_known_results();\n   ```\n\n3. **Validation Benefits**:\n   - **Consistent test input** ‚Üí Same image every time for reproducible testing\n   - **Known ground truth** ‚Üí Expected results documented for validation\n   - **Debug support** ‚Üí Consistent conditions for algorithm development\n   - **Performance measurement** ‚Üí Reproducible timing measurements\n\n#### üéØ Test Data Components\n\nThe system includes pre-loaded test data:\n- `test_img_buffer`: 800x480 RGB565 camera frame simulation\n- `test_nn_rgb`: 128x128 RGB888 prepared for face detection\n- `test_cropped_face_rgb`: 112x112 RGB888 face crop for recognition\n\nThis enables thorough testing of all pipeline stages with known inputs and expected outputs."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### üîß Development and Testing Workflow\n\nThe application provides comprehensive testing and validation capabilities:\n\n#### üìä Testing Phases\n\n**Phase 1: System Verification**\n- Test complete pipeline with known data\n- Validate face detection and recognition accuracy\n- Verify system stability and performance\n- Confirm hardware integration\n\n**Phase 2: Algorithm Validation**\n- Test individual function implementations\n- Compare outputs with reference implementations\n- Measure performance characteristics\n- Debug and optimize implementations\n\n**Phase 3: Real-time Integration**\n- Test with live camera input\n- Handle various faces and lighting conditions\n- Maintain real-time performance requirements\n- Validate robustness across different conditions\n\n### üîß Configuration Management\n\nThe system can be configured for different testing scenarios by modifying `Inc/app_config.h`:\n\n1. **Enable test mode**: Use predefined test images for consistent validation\n2. **Enable live mode**: Process real-time camera input\n3. **Debug configuration**: Add debugging output and timing measurements\n4. **Performance profiling**: Enable detailed performance monitoring"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üë®‚Äçüíª Part 3: Core Implementation Functions\n\n### Overview of Key Functions\n\nThe face recognition pipeline consists of several critical functions across multiple files:\n\n#### Image Processing Functions (`Src/crop_img.c`)\n| Function | Purpose | Input | Output |\n|----------|---------|-------|--------|\n| `img_rgb_to_chw_float` | Convert RGB to CHW float | RGB888 image | CHW float array |\n| `img_rgb_to_chw_float_norm` | Convert RGB to normalized CHW | RGB888 image | Normalized CHW float |\n| `img_crop_resize` | Crop and resize image | Source image | Resized crop |\n| `img_crop_align` | Face alignment with rotation | Face coordinates + eyes | Aligned face |\n| `img_crop_align565_to_888` | RGB565‚ÜíRGB888 + alignment | RGB565 + face data | RGB888 aligned face |\n\n#### Face Recognition Functions (`Src/face_utils.c`)\n| Function | Purpose | Input | Output |\n|----------|---------|-------|--------|\n| `embedding_cosine_similarity` | Calculate embedding similarity | Two embeddings | Similarity score |\n\n#### Embedding Management Functions (`Src/target_embedding.c`)\n| Function | Purpose | Input | Output |\n|----------|---------|-------|--------|\n| `embeddings_bank_init` | Initialize embedding storage | None | Void |\n| `embeddings_bank_add` | Add embedding to bank | Embedding vector | Success/failure |\n| `embeddings_bank_reset` | Clear all embeddings | None | Void |\n| `embeddings_bank_count` | Get current embedding count | None | Count |\n| `compute_target` | Compute average embedding | None (internal) | Void |\n\n### üéØ Implementation Architecture\n\nThese functions work together in a pipeline:\n1. **Basic Utilities**: Initialize storage and handle memory management\n2. **Image Processing**: Convert formats and extract regions of interest\n3. **Mathematical Operations**: Calculate similarity metrics\n4. **Data Management**: Handle embedding collections and averaging\n5. **Advanced Processing**: Perform alignment and format conversion\n\nThe implementation follows embedded systems best practices with efficient memory usage and optimized algorithms for real-time performance."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### üîß Function 1: `img_rgb_to_chw_float` - Layout Conversion\n\n#### Purpose\nConvert RGB image from HWC (Height√óWidth√óChannel) layout to CHW (Channel√óHeight√óWidth) layout in float format.\n\n#### Why This Matters\n- **Neural networks** often expect CHW layout (channel-first)\n- **OpenCV/PIL** typically uses HWC layout (channel-last)\n- **Memory layout** affects performance and compatibility\n\n#### Function Signature\n```c\nvoid img_rgb_to_chw_float(uint8_t *src_image, float32_t *dst_img,\n                          const uint32_t src_stride, const uint16_t width,\n                          const uint16_t height)\n```\n\n#### Input Layout (HWC):\n```\nsrc_image: [R‚ÇÄ,G‚ÇÄ,B‚ÇÄ, R‚ÇÅ,G‚ÇÅ,B‚ÇÅ, R‚ÇÇ,G‚ÇÇ,B‚ÇÇ, ...]\n           ‚îÇ  pixel 0  ‚îÇ  pixel 1  ‚îÇ  pixel 2  ‚îÇ\n```\n\n#### Output Layout (CHW):\n```\ndst_img: [R‚ÇÄ,R‚ÇÅ,R‚ÇÇ,...] [G‚ÇÄ,G‚ÇÅ,G‚ÇÇ,...] [B‚ÇÄ,B‚ÇÅ,B‚ÇÇ,...]\n         ‚îÇ Red channel ‚îÇ Green channel ‚îÇ Blue channel ‚îÇ\n```\n\n#### Complete Implementation\n\n```c\nvoid img_rgb_to_chw_float(uint8_t *src_image, float32_t *dst_img,\n                          const uint32_t src_stride, const uint16_t width,\n                          const uint16_t height)\n{\n    // Process each row of the image\n    for (uint16_t y = 0; y < height; y++) {\n        const uint8_t *pIn = src_image + y * src_stride;\n        \n        // Process each pixel in the row\n        for (uint16_t x = 0; x < width; x++) {\n            // Calculate linear index for destination\n            uint32_t dst_idx = y * width + x;\n            \n            // Convert and store in CHW layout\n            dst_img[dst_idx] = (float32_t)pIn[0];                           // Red channel\n            dst_img[height * width + dst_idx] = (float32_t)pIn[1];          // Green channel\n            dst_img[2 * height * width + dst_idx] = (float32_t)pIn[2];      // Blue channel\n            \n            pIn += 3;  // Move to next pixel (3 bytes per pixel)\n        }\n    }\n}\n```\n\n#### Key Implementation Details\n- **Memory Layout**: Efficient access pattern for both source and destination\n- **Index Calculations**: Proper handling of stride and channel offsets\n- **Type Conversion**: Safe conversion from uint8_t to float32_t\n- **Performance**: Linear memory access for optimal cache usage"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### üîß Function 2: `img_rgb_to_chw_float_norm` - Normalized Conversion\n\n#### Purpose\nConvert RGB image to CHW float format with normalization for neural network input.\n\n#### Normalization Formula\n```c\nnormalized_value = (pixel_value - 127.5f) / 127.5f\n```\n\nThis maps:\n- `0` ‚Üí `-1.0f`\n- `127.5` ‚Üí `0.0f` \n- `255` ‚Üí `1.0f`\n\n#### Complete Implementation\n\n```c\nvoid img_rgb_to_chw_float_norm(uint8_t *src_image, float32_t *dst_img,\n                               const uint32_t src_stride, const uint16_t width,\n                               const uint16_t height)\n{\n    // Process each row of the image\n    for (uint16_t y = 0; y < height; y++) {\n        const uint8_t *pIn = src_image + y * src_stride;\n        \n        // Process each pixel in the row\n        for (uint16_t x = 0; x < width; x++) {\n            // Calculate linear index for destination\n            uint32_t dst_idx = y * width + x;\n            \n            // Convert and normalize to [-1, 1] range in CHW layout\n            dst_img[dst_idx] = ((float32_t)pIn[0] - 127.5f) / 127.5f;                           // Red\n            dst_img[height * width + dst_idx] = ((float32_t)pIn[1] - 127.5f) / 127.5f;          // Green\n            dst_img[2 * height * width + dst_idx] = ((float32_t)pIn[2] - 127.5f) / 127.5f;      // Blue\n            \n            pIn += 3;  // Move to next pixel\n        }\n    }\n}\n```\n\n#### Alternative Efficient Implementation\n```c\nvoid img_rgb_to_chw_float_norm(uint8_t *src_image, float32_t *dst_img,\n                               const uint32_t src_stride, const uint16_t width,\n                               const uint16_t height)\n{\n    const float norm_factor = 1.0f / 127.5f;\n    const float offset = -127.5f;\n    \n    for (uint16_t y = 0; y < height; y++) {\n        const uint8_t *pIn = src_image + y * src_stride;\n        \n        for (uint16_t x = 0; x < width; x++) {\n            uint32_t dst_idx = y * width + x;\n            \n            // Optimized normalization with pre-calculated constants\n            for (uint8_t c = 0; c < 3; c++) {\n                dst_img[c * height * width + dst_idx] = ((float32_t)pIn[c] + offset) * norm_factor;\n            }\n            \n            pIn += 3;\n        }\n    }\n}\n```\n\n#### Key Features\n- **Consistent normalization**: Standard [-1, 1] range expected by neural networks\n- **Optimized calculations**: Pre-computed constants for better performance\n- **Numerical stability**: Proper handling of floating-point precision"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Function 3: `img_crop_resize` (‚≠ê‚≠ê‚≠ê Intermediate)\n",
    "\n",
    "#### Purpose\n",
    "Crop a rectangular region from source image and resize it to destination size using nearest neighbor interpolation.\n",
    "\n",
    "#### Function Signature\n",
    "```c\n",
    "void img_crop_resize(uint8_t *src_image, uint8_t *dst_img,\n",
    "                     const uint16_t src_width, const uint16_t src_height,\n",
    "                     const uint16_t dst_width, const uint16_t dst_height,\n",
    "                     const uint16_t bpp, int x0, int y0,\n",
    "                     int crop_width, int crop_height)\n",
    "```\n",
    "\n",
    "#### Parameters Explained\n",
    "- `src_image`: Source image buffer\n",
    "- `dst_img`: Destination image buffer  \n",
    "- `src_width/height`: Source image dimensions\n",
    "- `dst_width/height`: Destination image dimensions\n",
    "- `bpp`: Bytes per pixel (usually 3 for RGB)\n",
    "- `x0, y0`: Top-left corner of crop region\n",
    "- `crop_width/height`: Size of crop region\n",
    "\n",
    "#### üí° Implementation Hints\n",
    "\n",
    "1. **Understand the Mapping**:\n",
    "   ```c\n",
    "   // For each destination pixel (dst_x, dst_y):\n",
    "   // Find corresponding source pixel:\n",
    "   src_x = x0 + (dst_x * crop_width) / dst_width;\n",
    "   src_y = y0 + (dst_y * crop_height) / dst_height;\n",
    "   ```\n",
    "\n",
    "2. **Bounds Checking** (Critical!):\n",
    "   ```c\n",
    "   if (src_x < 0) src_x = 0;\n",
    "   if (src_x >= src_width) src_x = src_width - 1;\n",
    "   if (src_y < 0) src_y = 0;\n",
    "   if (src_y >= src_height) src_y = src_height - 1;\n",
    "   ```\n",
    "\n",
    "3. **Pixel Copying**:\n",
    "   ```c\n",
    "   const uint8_t *pIn = src_image + (src_y * src_width + src_x) * bpp;\n",
    "   uint8_t *pOut = dst_img + (dst_y * dst_width + dst_x) * bpp;\n",
    "   \n",
    "   for (int c = 0; c < bpp; c++) {\n",
    "       pOut[c] = pIn[c];\n",
    "   }\n",
    "   ```\n",
    "\n",
    "4. **Complete Implementation Template**:\n",
    "   ```c\n",
    "   void img_crop_resize(uint8_t *src_image, uint8_t *dst_img,\n",
    "                        const uint16_t src_width, const uint16_t src_height,\n",
    "                        const uint16_t dst_width, const uint16_t dst_height,\n",
    "                        const uint16_t bpp, int x0, int y0,\n",
    "                        int crop_width, int crop_height)\n",
    "   {\n",
    "       for (int dst_y = 0; dst_y < dst_height; dst_y++) {\n",
    "           // TODO: Calculate source Y coordinate\n",
    "           int src_y = y0 + (dst_y * crop_height) / dst_height;\n",
    "           // TODO: Apply bounds checking for src_y\n",
    "           \n",
    "           for (int dst_x = 0; dst_x < dst_width; dst_x++) {\n",
    "               // TODO: Calculate source X coordinate  \n",
    "               int src_x = x0 + (dst_x * crop_width) / dst_width;\n",
    "               // TODO: Apply bounds checking for src_x\n",
    "               \n",
    "               // TODO: Calculate source and destination pointers\n",
    "               // TODO: Copy pixel data (all channels)\n",
    "           }\n",
    "       }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "#### üß™ Testing Your Implementation\n",
    "- **Test with simple crop**: x0=0, y0=0, crop_width=src_width (should be identical)\n",
    "- **Test scaling**: Compare 1:1 crop vs 2:1 downscale\n",
    "- **Test bounds**: Crop near image edges\n",
    "- **Visual verification**: Check if cropped region looks correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Function 4: `img_crop_align` (‚≠ê‚≠ê‚≠ê‚≠ê Advanced - Optional)\n",
    "\n",
    "#### Purpose\n",
    "Crop and align face image based on eye positions, applying rotation to normalize face orientation.\n",
    "\n",
    "#### Why Face Alignment Matters\n",
    "- **Improves recognition accuracy**: Consistent face orientation\n",
    "- **Normalizes pose variations**: Reduces head tilt effects  \n",
    "- **Standardizes input**: Makes recognition more robust\n",
    "\n",
    "#### Mathematical Concepts\n",
    "\n",
    "1. **Rotation Angle Calculation**:\n",
    "   ```c\n",
    "   float angle = -atan2f(right_eye_y - left_eye_y, right_eye_x - left_eye_x);\n",
    "   ```\n",
    "\n",
    "2. **Rotation Matrix**:\n",
    "   ```c\n",
    "   float cos_a = cosf(angle);\n",
    "   float sin_a = sinf(angle);\n",
    "   \n",
    "   // Inverse rotation to map destination to source:\n",
    "   src_x = x_center + (nx * width) * cos_a + (ny * height) * sin_a;\n",
    "   src_y = y_center + (ny * height) * cos_a - (nx * width) * sin_a;\n",
    "   ```\n",
    "\n",
    "#### üí° Implementation Hints\n",
    "\n",
    "This is an **advanced function**. Focus on the basic functions first. If you want to attempt it:\n",
    "\n",
    "1. **Start with rotation understanding**: Study 2D rotation matrices\n",
    "2. **Use instructor implementation**: Compare your approach\n",
    "3. **Test incrementally**: Small rotations first\n",
    "4. **Visual debugging**: Check if rotation looks correct\n",
    "\n",
    "#### üéØ Learning Focus\n",
    "- **Understand the concept**: Why face alignment helps\n",
    "- **Study the math**: Rotation matrices and coordinate transforms\n",
    "- **Observe the results**: Compare aligned vs non-aligned faces\n",
    "\n",
    "‚ö†Ô∏è **Recommendation**: Implement basic functions first, then return to this if time permits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Function 5: `img_crop_align565_to_888` (‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Expert - Optional)\n",
    "\n",
    "#### Purpose\n",
    "Advanced function combining RGB565‚ÜíRGB888 format conversion with face alignment.\n",
    "\n",
    "#### RGB565 Format Understanding\n",
    "```\n",
    "RGB565: 16-bit format\n",
    "Bits: [R‚ÇÑR‚ÇÉR‚ÇÇR‚ÇÅR‚ÇÄ G‚ÇÖG‚ÇÑG‚ÇÉG‚ÇÇG‚ÇÅG‚ÇÄ B‚ÇÑB‚ÇÉB‚ÇÇB‚ÇÅB‚ÇÄ]\n",
    "      ‚îÇ    5 bits   ‚îÇ    6 bits    ‚îÇ   5 bits  ‚îÇ\n",
    "```\n",
    "\n",
    "#### RGB565 to RGB888 Conversion\n",
    "```c\n",
    "uint16_t pixel = *((uint16_t*)source_ptr);\n",
    "uint8_t red   = ((pixel >> 11) & 0x1F) << 3;  // 5‚Üí8 bits\n",
    "uint8_t green = ((pixel >> 5) & 0x3F) << 2;   // 6‚Üí8 bits  \n",
    "uint8_t blue  = (pixel & 0x1F) << 3;          // 5‚Üí8 bits\n",
    "```\n",
    "\n",
    "#### üéØ Expert Challenge\n",
    "This function combines:\n",
    "- **Format conversion** (RGB565‚ÜíRGB888)\n",
    "- **Face alignment** (rotation matrix)\n",
    "- **Memory management** (different stride calculations)\n",
    "\n",
    "‚ö†Ô∏è **Recommendation**: Only attempt after mastering all previous functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### üîß Function 6: `embedding_cosine_similarity` - Similarity Calculation\n\n#### Purpose\nCalculate the cosine similarity between two face embedding vectors to determine how similar two faces are.\n\n#### Mathematical Formula\n```\ncosine_similarity = dot_product(A, B) / (norm(A) * norm(B))\n\nWhere:\n- dot_product(A, B) = Œ£(A[i] * B[i])\n- norm(A) = sqrt(Œ£(A[i]¬≤))\n- norm(B) = sqrt(Œ£(B[i]¬≤))\n```\n\n#### Complete Implementation\n\n```c\nfloat embedding_cosine_similarity(const float *emb1, const float *emb2, uint32_t len)\n{\n    // Input validation\n    if (!emb1 || !emb2 || len == 0) {\n        return 0.0f;\n    }\n    \n    // Single-pass calculation for efficiency\n    float dot_product = 0.0f;\n    float norm1_squared = 0.0f;\n    float norm2_squared = 0.0f;\n    \n    for (uint32_t i = 0; i < len; i++) {\n        const float val1 = emb1[i];\n        const float val2 = emb2[i];\n        \n        dot_product += val1 * val2;        // Accumulate dot product\n        norm1_squared += val1 * val1;      // Accumulate norm squared for emb1\n        norm2_squared += val2 * val2;      // Accumulate norm squared for emb2\n    }\n    \n    // Handle zero norms to avoid division by zero\n    if (norm1_squared == 0.0f || norm2_squared == 0.0f) {\n        return 0.0f;\n    }\n    \n    // Calculate and return cosine similarity\n    return dot_product / sqrtf(norm1_squared * norm2_squared);\n}\n```\n\n#### Why Cosine Similarity Matters\n- **Face Recognition Core**: Main algorithm for comparing faces\n- **Angle-based Comparison**: Measures angle between vectors, not magnitude\n- **Robust to Scale**: Works regardless of embedding vector length\n- **Interpretable Results**: -1.0 (opposite) to +1.0 (identical)\n\n#### Optimization Notes\n- **Single-pass algorithm**: Calculates all components in one loop\n- **Efficient memory access**: Linear traversal of embedding vectors\n- **Numerical stability**: Proper handling of edge cases and zero vectors"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### üîß Embedding Management Functions - Complete Implementation\n\n#### Purpose Overview\nThese functions manage a collection (bank) of face embeddings to create a robust representation of a target person. Multiple embeddings are averaged to handle variations in lighting, angles, and expressions.\n\n#### Key Concepts\n- **Embedding Bank**: Array storing multiple embeddings (up to 10) for one person\n- **Target Embedding**: Average of all embeddings in the bank (normalized)\n- **Normalization**: Ensures embeddings have unit length for cosine similarity\n- **Bank Management**: Add, reset, count operations\n\n---\n\n### Function 7: `embeddings_bank_init`\n\n```c\nvoid embeddings_bank_init(void)\n{\n    bank_count = 0;\n    memset(embedding_bank, 0, sizeof(embedding_bank));\n    memset(target_embedding, 0, sizeof(target_embedding));\n}\n```\n\n### Function 8: `embeddings_bank_count`\n\n```c\nint embeddings_bank_count(void)\n{\n    return bank_count;\n}\n```\n\n### Function 9: `embeddings_bank_reset`\n\n```c\nvoid embeddings_bank_reset(void)\n{\n    embeddings_bank_init();\n}\n```\n\n### Function 10: `embeddings_bank_add`\n\n```c\nint embeddings_bank_add(const float *embedding)\n{\n    // Check if bank is full\n    if (bank_count >= EMBEDDING_BANK_SIZE) {\n        return -1;\n    }\n    \n    // Calculate norm of input embedding\n    float norm = 0.0f;\n    for (int i = 0; i < EMBEDDING_SIZE; i++) {\n        norm += embedding[i] * embedding[i];\n    }\n    norm = sqrtf(norm);\n    \n    // Check for zero norm\n    if (norm == 0.0f) {\n        return -1;\n    }\n    \n    // Normalize and store embedding\n    for (int i = 0; i < EMBEDDING_SIZE; i++) {\n        embedding_bank[bank_count][i] = embedding[i] / norm;\n    }\n    \n    // Increment bank count\n    bank_count++;\n    \n    // Recompute target embedding\n    compute_target();\n    \n    return bank_count;\n}\n```\n\n### Function 11: `compute_target` (Static Function)\n\n```c\nstatic void compute_target(void)\n{\n    // Handle empty bank\n    if (bank_count == 0) {\n        memset(target_embedding, 0, sizeof(target_embedding));\n        return;\n    }\n    \n    // Calculate sum of all embeddings\n    float sum[EMBEDDING_SIZE];\n    memset(sum, 0, sizeof(sum));\n    \n    for (int n = 0; n < bank_count; n++) {\n        for (int i = 0; i < EMBEDDING_SIZE; i++) {\n            sum[i] += embedding_bank[n][i];\n        }\n    }\n    \n    // Calculate average\n    for (int i = 0; i < EMBEDDING_SIZE; i++) {\n        target_embedding[i] = sum[i] / (float)bank_count;\n    }\n    \n    // Normalize target embedding\n    float norm = 0.0f;\n    for (int i = 0; i < EMBEDDING_SIZE; i++) {\n        norm += target_embedding[i] * target_embedding[i];\n    }\n    norm = sqrtf(norm);\n    \n    if (norm > 0.0f) {\n        for (int i = 0; i < EMBEDDING_SIZE; i++) {\n            target_embedding[i] /= norm;\n        }\n    }\n}\n```\n\n#### Implementation Benefits\n- **Robust representation**: Multiple embeddings improve recognition accuracy\n- **Normalized embeddings**: Unit length vectors for consistent similarity calculations\n- **Efficient averaging**: Single-pass computation with automatic target updates\n- **Memory management**: Fixed-size arrays with bounds checking"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üß™ Part 4: Testing and Validation Strategy\n\n### Comprehensive Validation Approach\n\n#### Development Workflow\n\n1. **Build Verification**:\n   ```c\n   // In app_config.h - configure for testing\n   #define ENABLE_DEBUG_OUTPUT\n   #define ENABLE_PERFORMANCE_MONITORING\n   ```\n\n2. **Function-Level Testing**:\n   - Unit test each function individually\n   - Validate with known input/output pairs\n   - Compare performance against reference implementations\n   - Test edge cases and boundary conditions\n\n3. **Integration Testing**:\n   - Test complete pipeline with known data\n   - Validate face detection accuracy\n   - Verify face recognition performance\n   - Confirm real-time processing capabilities\n\n#### Testing Strategy per Function\n\n**For Image Processing Functions**:\n```c\n// Validation approach for img_rgb_to_chw_float\nvoid test_img_rgb_to_chw_float() {\n    // Test with known input pattern\n    uint8_t test_input[3*2*2] = {255,0,0, 0,255,0, 0,0,255, 128,128,128};\n    float test_output[3*2*2];\n    \n    img_rgb_to_chw_float(test_input, test_output, 6, 2, 2);\n    \n    // Verify CHW layout\n    assert(test_output[0] == 255.0f);  // First red pixel\n    assert(test_output[4] == 0.0f);    // First green pixel  \n    assert(test_output[8] == 0.0f);    // First blue pixel\n}\n```\n\n**For Mathematical Functions**:\n```c\n// Validation approach for cosine similarity\nvoid test_cosine_similarity() {\n    // Test with known vectors\n    float vec1[] = {1.0f, 0.0f, 0.0f};\n    float vec2[] = {1.0f, 0.0f, 0.0f};\n    float similarity = embedding_cosine_similarity(vec1, vec2, 3);\n    \n    assert(fabs(similarity - 1.0f) < 1e-6);  // Should be 1.0 (identical)\n}\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Debugging and Validation Tools\n\n#### üö® Debug Console Output Analysis\n\n**Implementation Validation Messages**:\n```\n‚úÖ Good signs:\n\"üîÑ Loading test image buffers...\"\n\"üéØ Face detected at (x,y) with confidence...\"\n\"‚úÖ Face cropped successfully - size: 112x112\"\n\"üî¢ Embedding generated: norm=1.000\"\n\"üìä Similarity calculated: 0.847\"\n\n‚ùå Warning signs:\n\"‚ùå No faces detected in current frame\"\n\"‚ö†Ô∏è Face detection confidence too low: 0.23\"\n\"üí• Embedding normalization failed\"\n\"üö´ Similarity calculation error\"\n```\n\n#### üîç Performance Monitoring\n\n**Real-time Performance Metrics**:\n```c\n// Add to main loop for performance monitoring\ntypedef struct {\n    uint32_t face_detection_ms;\n    uint32_t face_cropping_ms;\n    uint32_t embedding_generation_ms;\n    uint32_t similarity_calculation_ms;\n    uint32_t total_pipeline_ms;\n} performance_metrics_t;\n\nvoid monitor_performance() {\n    uint32_t start_time = HAL_GetTick();\n    \n    // Execute pipeline stage\n    run_face_detection();\n    \n    uint32_t elapsed = HAL_GetTick() - start_time;\n    metrics.face_detection_ms = elapsed;\n    \n    printf(\"Face detection: %lu ms\\n\", elapsed);\n}\n```\n\n#### üéØ Expected Performance Targets\n\n```\nüìä System Performance Goals:\n- Face Detection: < 100ms per frame\n- Face Cropping: < 20ms per face\n- Embedding Generation: < 50ms per face\n- Similarity Calculation: < 5ms per comparison\n- Total Pipeline: < 200ms for single face\n- Memory Usage: < 80% of available RAM\n- CPU Usage: < 90% average\n```\n\n#### üîß Troubleshooting Guide\n\n**Performance Issues**:\n```c\n// Profile individual functions\n#define PROFILE_FUNCTION(func_call) do { \\\n    uint32_t start = HAL_GetTick(); \\\n    func_call; \\\n    uint32_t end = HAL_GetTick(); \\\n    printf(#func_call \": %lu ms\\n\", end - start); \\\n} while(0)\n\n// Usage:\nPROFILE_FUNCTION(img_rgb_to_chw_float(src, dst, stride, w, h));\n```\n\n**Memory Issues**:\n```c\n// Check stack usage\nvoid check_stack_usage() {\n    uint32_t stack_free = uxTaskGetStackHighWaterMark(NULL);\n    printf(\"Stack free: %lu bytes\\n\", stack_free * sizeof(StackType_t));\n}\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Part 5: Performance Analysis and Optimization\n",
    "\n",
    "### Understanding Embedded Constraints\n",
    "\n",
    "#### Memory Limitations\n",
    "```\n",
    "STM32N6 Memory Map:\n",
    "- Flash: 2MB (program code, constants)\n",
    "- RAM: 1.5MB (variables, stack, heap)\n",
    "- PSRAM: External memory (image buffers)\n",
    "```\n",
    "\n",
    "#### Performance Considerations\n",
    "\n",
    "1. **CPU Usage**:\n",
    "   - ARM Cortex-M55 @ 600MHz\n",
    "   - Integer operations preferred over float\n",
    "   - SIMD instructions available (advanced)\n",
    "\n",
    "2. **Memory Access Patterns**:\n",
    "   - Sequential access faster than random\n",
    "   - Cache-friendly algorithms preferred\n",
    "   - Minimize memory allocations\n",
    "\n",
    "3. **Image Processing Optimization**:\n",
    "   ```c\n",
    "   // Efficient (cache-friendly):\n",
    "   for (y = 0; y < height; y++) {\n",
    "       for (x = 0; x < width; x++) {\n",
    "           // Process pixel at (x,y)\n",
    "       }\n",
    "   }\n",
    "   \n",
    "   // Less efficient (cache-unfriendly):\n",
    "   for (x = 0; x < width; x++) {\n",
    "       for (y = 0; y < height; y++) {\n",
    "           // Process pixel at (x,y) - jumps memory locations\n",
    "       }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "### üìà Performance Measurement\n",
    "\n",
    "#### Using STM32 Performance Counters\n",
    "```c\n",
    "// Add to your function for timing:\n",
    "uint32_t start_time = HAL_GetTick();\n",
    "img_rgb_to_chw_float(...);\n",
    "uint32_t end_time = HAL_GetTick();\n",
    "printf(\"Function took %lu ms\\n\", end_time - start_time);\n",
    "```\n",
    "\n",
    "#### Expected Performance Targets\n",
    "```\n",
    "Function Performance Goals (128x128 image):\n",
    "- img_rgb_to_chw_float: < 5ms\n",
    "- img_crop_resize: < 10ms  \n",
    "- img_crop_align: < 15ms\n",
    "```\n",
    "\n",
    "### üöÄ Optimization Techniques\n",
    "\n",
    "#### 1. Loop Unrolling\n",
    "```c\n",
    "// Instead of:\n",
    "for (int c = 0; c < 3; c++) {\n",
    "    dst[c] = src[c];\n",
    "}\n",
    "\n",
    "// Use:\n",
    "dst[0] = src[0];  // Red\n",
    "dst[1] = src[1];  // Green  \n",
    "dst[2] = src[2];  // Blue\n",
    "```\n",
    "\n",
    "#### 2. Pointer Arithmetic\n",
    "```c\n",
    "// Efficient pointer advancement:\n",
    "const uint8_t *pIn = src_image;\n",
    "float32_t *pOut = dst_img;\n",
    "for (int i = 0; i < total_pixels; i++) {\n",
    "    *pOut++ = (float32_t)*pIn++;\n",
    "}\n",
    "```\n",
    "\n",
    "#### 3. Compile-Time Constants\n",
    "```c\n",
    "// Use #define for known constants:\n",
    "#define FACE_SIZE 112\n",
    "#define CHANNELS 3\n",
    "// Compiler can optimize better with constants\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üéØ Part 6: System Integration and Validation\n\n### Complete System Integration\n\n#### Final Integration Testing\n\n**System-Level Validation Steps**:\n\n1. **Hardware Integration Test**:\n   - Verify camera input capture\n   - Confirm LCD display output\n   - Test user input (buttons/touch)\n   - Validate real-time performance\n\n2. **Algorithm Integration Test**:\n   - Complete pipeline with live camera input\n   - Face detection ‚Üí cropping ‚Üí recognition flow\n   - Multi-face handling capabilities\n   - Recognition accuracy validation\n\n3. **Performance Integration Test**:\n   - Real-time processing validation\n   - Memory usage profiling\n   - Power consumption measurement\n   - Thermal stability testing\n\n#### Success Criteria\n\n‚úÖ **Integration Success Indicators**:\n- System boots and initializes without errors\n- Camera captures frames at target framerate\n- Face detection finds faces with >90% accuracy\n- Face recognition distinguishes between different people\n- Real-time performance meets target specifications\n- System runs continuously without memory leaks or crashes\n\n‚úÖ **Performance Success Metrics**:\n- Pipeline processes faces within 200ms target\n- Memory usage remains stable over extended operation\n- Recognition accuracy >95% for enrolled faces\n- False positive rate <5% for unknown faces\n\n#### Deployment Validation\n\n**Production Readiness Checklist**:\n```c\n// System health monitoring\ntypedef struct {\n    uint32_t frames_processed;\n    uint32_t faces_detected;\n    uint32_t faces_recognized;\n    uint32_t system_uptime_ms;\n    float average_fps;\n    uint32_t memory_usage_bytes;\n} system_health_t;\n\nvoid validate_system_health() {\n    system_health_t health;\n    \n    // Collect metrics\n    health.frames_processed = get_frame_count();\n    health.average_fps = calculate_average_fps();\n    health.memory_usage_bytes = get_memory_usage();\n    \n    // Validate against requirements\n    assert(health.average_fps >= TARGET_FPS);\n    assert(health.memory_usage_bytes < MAX_MEMORY_USAGE);\n    \n    printf(\"‚úÖ System health validation passed\\n\");\n}\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting Integration Issues\n",
    "\n",
    "#### üö® \"Works in DUMMY mode but fails with camera\"\n",
    "\n",
    "**Possible Causes**:\n",
    "1. **Timing issues**: Camera input changes while processing\n",
    "2. **Memory alignment**: Camera data has different stride\n",
    "3. **Format differences**: Camera RGB vs expected format\n",
    "\n",
    "**Debug Steps**:\n",
    "```c\n",
    "// Add debug prints to check input:\n",
    "printf(\"Camera input: first pixel RGB=(%d,%d,%d)\\n\", \n",
    "       src_image[0], src_image[1], src_image[2]);\n",
    "printf(\"Image stride: %d, expected: %d\\n\", actual_stride, expected_stride);\n",
    "```\n",
    "\n",
    "#### üö® \"Performance degradation with your implementation\"\n",
    "\n",
    "**Optimization Priority**:\n",
    "1. **Profile each function**: Find the bottleneck\n",
    "2. **Check memory access patterns**: Ensure cache efficiency\n",
    "3. **Reduce function calls**: Inline small functions\n",
    "4. **Use instructor implementation**: As performance reference\n",
    "\n",
    "#### üö® \"Intermittent crashes or artifacts\"\n",
    "\n",
    "**Investigation Steps**:\n",
    "1. **Enable stack monitoring**: Check for stack overflow\n",
    "2. **Add buffer guards**: Detect buffer overruns\n",
    "3. **Stress test**: Run for extended periods\n",
    "4. **Memory debugging**: Check for corruption patterns\n",
    "\n",
    "### Performance Benchmarking\n",
    "\n",
    "#### Key Metrics to Monitor\n",
    "```\n",
    "üìä System Performance Targets:\n",
    "- Face Detection: < 100ms per frame\n",
    "- Face Cropping: < 20ms per face\n",
    "- Face Recognition: < 50ms per face\n",
    "- Total Pipeline: < 200ms for single face\n",
    "- Memory Usage: < 80% of available RAM\n",
    "- CPU Usage: < 90% average\n",
    "```\n",
    "\n",
    "#### Measuring Real Performance\n",
    "```c\n",
    "// Add performance monitoring:\n",
    "typedef struct {\n",
    "    uint32_t detection_time_ms;\n",
    "    uint32_t cropping_time_ms;\n",
    "    uint32_t recognition_time_ms;\n",
    "    uint32_t total_time_ms;\n",
    "} performance_stats_t;\n",
    "\n",
    "// Use in main loop:\n",
    "uint32_t start = HAL_GetTick();\n",
    "// ... perform operation ...\n",
    "stats.operation_time_ms = HAL_GetTick() - start;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Configurable alerts and thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}