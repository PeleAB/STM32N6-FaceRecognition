{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to STM32 Conversion using ST Edge AI\n",
    "\n",
    "This notebook demonstrates how to convert machine learning models to STM32-compatible code using ST Edge AI tools.\n",
    "\n",
    "We'll convert:\n",
    "1. CenterFace TFLite model for face detection\n",
    "2. MobileFaceNet ONNX model for face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ stedgeai found at: /home/vboxuser/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/10.1.0/Utilities/linux/stedgeai\n",
      "✅ stedgeai is executable and responding\n",
      "✅ Using STM32CubeMX compatible version (v2.1.0)\n",
      "\n",
      "=== CPU Capabilities Check ===\n",
      "✅ AVX support detected\n",
      "CenterFace model exists: True\n",
      "MobileFaceNet model exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Use STM32CubeMX version that works (v2.1.0 instead of v2.2.0)\n",
    "STEDGEAI_PATH = '/home/vboxuser/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/10.1.0/Utilities/linux/stedgeai'\n",
    "\n",
    "# Test if stedgeai is accessible at the STM32CubeMX path\n",
    "if os.path.exists(STEDGEAI_PATH):\n",
    "    print(f\"✅ stedgeai found at: {STEDGEAI_PATH}\")\n",
    "    \n",
    "    # Test if it's executable and check for AVX requirements\n",
    "    try:\n",
    "        result = subprocess.run([STEDGEAI_PATH, '--help'], capture_output=True, text=True, timeout=5)\n",
    "        print(\"✅ stedgeai is executable and responding\")\n",
    "        # Check version\n",
    "        if 'v2.1.0' in result.stdout:\n",
    "            print(\"✅ Using STM32CubeMX compatible version (v2.1.0)\")\n",
    "        else:\n",
    "            print(\"ℹ️  Version info not found in help output\")\n",
    "    except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:\n",
    "        print(f\"⚠️  stedgeai found but may have issues: {e}\")\n",
    "    except Exception as e:\n",
    "        if \"AVX\" in str(e) or \"SIGILL\" in str(e):\n",
    "            print(\"❌ AVX instruction set not available - this is likely the issue\")\n",
    "            print(\"Solutions:\")\n",
    "            print(\"1. Enable AVX in VM settings (see instructions)\")\n",
    "            print(\"2. Use a different machine with AVX support\")\n",
    "            print(\"3. Try running stedgeai with compatibility flags\")\n",
    "else:\n",
    "    print(f\"❌ stedgeai not found at: {STEDGEAI_PATH}\")\n",
    "    print(\"Please verify the installation path\")\n",
    "\n",
    "# Check CPU capabilities\n",
    "print(\"\\n=== CPU Capabilities Check ===\")\n",
    "try:\n",
    "    result = subprocess.run(['lscpu'], capture_output=True, text=True)\n",
    "    cpu_info = result.stdout\n",
    "    if 'avx' in cpu_info.lower():\n",
    "        print(\"✅ AVX support detected\")\n",
    "    else:\n",
    "        print(\"❌ No AVX support detected\")\n",
    "        print(\"This VM needs AVX enabled in hypervisor settings\")\n",
    "except:\n",
    "    print(\"Could not check CPU capabilities\")\n",
    "\n",
    "# Set up paths\n",
    "models_dir = Path('./onnx_tflite_src')\n",
    "output_dir = Path('./converted_models')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Model paths\n",
    "centerface_model = models_dir / 'centerface.tflite'\n",
    "mobilefacenet_model = models_dir / 'mobilefacenet_int8_faces.onnx'\n",
    "\n",
    "print(f\"CenterFace model exists: {centerface_model.exists()}\")\n",
    "print(f\"MobileFaceNet model exists: {mobilefacenet_model.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for ST Edge AI\n",
    "\n",
    "Create configuration files for optimized STM32 generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Layout Strategy\n",
    "\n",
    "The two models use different memory pool configurations to avoid conflicts in external flash:\n",
    "\n",
    "**Memory Pool Assignments:**\n",
    "- **CenterFace (model1.mpool)**: External flash starts at `0x71000000` (Face Detection)\n",
    "- **MobileFaceNet (model2.mpool)**: External flash starts at `0x72000000` (Face Recognition)\n",
    "\n",
    "\n",
    "**Flash Memory Layout:**\n",
    "```\n",
    "0x70000000 - 0x700FFFFF: Bootloader code (1MB)\n",
    "0x70100000 - 0x709FFFFF: Application code (8MB)\n",
    "0x70A00000 - 0x70FFFFFF: Reserved space (6MB)\n",
    "0x71000000 - 0x71FFFFFF: Face Detection model data (16MB)\n",
    "0x72000000 - 0x72FFFFFF: Face Recognition model data (16MB)\n",
    "0x73000000 - 0x74FFFFFF: Available for other uses (32MB)\n",
    "```\n",
    "\n",
    "This layout ensures:\n",
    "- No model data overwrites the bootloader or application\n",
    "- Both models can coexist without conflicts\n",
    "- Efficient memory utilization on STM32N6 with external flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration files created with proper memory pool assignments:\n",
      "- CenterFace (Face Detection): model1.mpool (external flash @ 0x71000000)\n",
      "- MobileFaceNet (Face Recognition): model2.mpool (external flash @ 0x72000000)\n"
     ]
    }
   ],
   "source": [
    "# Create neural art configuration for face detection (CenterFace)\n",
    "# Uses model1.mpool with external flash at 0x71000000\n",
    "face_detection_config = {\n",
    "    \"Globals\": {},\n",
    "    \"Profiles\": {\n",
    "        \"centerface\": {\n",
    "            \"memory_pool\": \"./memory_pools/model1.mpool\",\n",
    "            \"options\": \"-O0 --all-buffers-info --mvei --cache-maintenance --Oalt-sched  --enable-virtual-mem-pools --Omax-ca-pipe 4 --Ocache-opt --Os --enable-epoch-controller\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create neural art configuration for face recognition (MobileFaceNet)\n",
    "# Uses model2.mpool with external flash at 0x72000000\n",
    "face_recognition_config = {\n",
    "    \"Globals\": {},\n",
    "    \"Profiles\": {\n",
    "        \"mobilefacenet\": {\n",
    "            \"memory_pool\": \"./memory_pools/model2.mpool\",\n",
    "            \"options\": \"-O0 --all-buffers-info --mvei --cache-maintenance --Oalt-sched --enable-virtual-mem-pools --Omax-ca-pipe 4 --Ocache-opt --Os --enable-epoch-controller\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configurations\n",
    "with open('face_detection_config.json', 'w') as f:\n",
    "    json.dump(face_detection_config, f, indent=4)\n",
    "\n",
    "with open('face_recognition_config.json', 'w') as f:\n",
    "    json.dump(face_recognition_config, f, indent=4)\n",
    "\n",
    "print(\"Configuration files created with proper memory pool assignments:\")\n",
    "print(\"- CenterFace (Face Detection): model1.mpool (external flash @ 0x71000000)\")\n",
    "print(\"- MobileFaceNet (Face Recognition): model2.mpool (external flash @ 0x72000000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert CenterFace TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def run_stedgeai_conversion(model_path,\n",
    "                            output_name,\n",
    "                            target=\"stm32n6\",\n",
    "                            input_data_type=\"uint8\",\n",
    "                            neural_art_config=\"\",\n",
    "                            profile_config=\"\"):\n",
    "    \"\"\"Run ST Edge AI conversion but show a single, updating progress bar line in Jupyter.\"\"\"\n",
    "    if not os.path.exists(STEDGEAI_PATH):\n",
    "        print(f\"Error: stedgeai not found at {STEDGEAI_PATH}\")\n",
    "        return False\n",
    "\n",
    "    # disable any built‑in progress suppression\n",
    "    env = os.environ.copy()\n",
    "    env.pop(\"TQDM_DISABLE\", None)\n",
    "\n",
    "    cmd = [\n",
    "        STEDGEAI_PATH, \"generate\",\n",
    "        \"--name\",           str(output_name),\n",
    "        \"--model\",          str(model_path),\n",
    "        \"--target\",         target,\n",
    "        \"--st-neural-art\",  f\"{profile_config}@{neural_art_config}\",\n",
    "        \"--input-data-type\",input_data_type,\n",
    "        \"--output\",         str(output_dir)\n",
    "    ]\n",
    "\n",
    "    print(f\"Running: {' '.join(cmd)}\\n\")\n",
    "\n",
    "    # Launch the process and stream its combined stdout+stderr\n",
    "    proc = subprocess.Popen(cmd,\n",
    "                            stdout=subprocess.PIPE,\n",
    "                            stderr=subprocess.STDOUT,\n",
    "                            text=True,\n",
    "                            bufsize=1,\n",
    "                            env=env)\n",
    "\n",
    "    try:\n",
    "        for raw_line in proc.stdout:\n",
    "            # strip trailing newline but keep any leading 'PASS:' or similar\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            # overwrite previous output instead of appending\n",
    "            clear_output(wait=True)\n",
    "            print(line)\n",
    "\n",
    "        proc.wait()\n",
    "        if proc.returncode != 0:\n",
    "            print(f\"\\n❌ Conversion failed (exit code {proc.returncode})\")\n",
    "            return False\n",
    "\n",
    "        print(\"\\n✅ Conversion completed successfully.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        proc.kill()\n",
    "        clear_output(wait=True)\n",
    "        print(f\"\\n❌ Error during conversion: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time (generate): 17.781s\n",
      "\n",
      "✅ Conversion completed successfully.\n",
      "✅ CenterFace model conversion completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Convert CenterFace model\n",
    "print(\"Converting CenterFace TFLite model...\")\n",
    "centerface_success = run_stedgeai_conversion(\n",
    "    centerface_model, \n",
    "    'face_detection',\n",
    "    target=\"stm32n6\",\n",
    "    input_data_type=\"float32\",\n",
    "    neural_art_config = \"face_detection_config.json\",\n",
    "    profile_config = \"centerface\"\n",
    ")\n",
    "\n",
    "if centerface_success:\n",
    "    print(\"✅ CenterFace model conversion completed successfully\")\n",
    "else:\n",
    "    print(\"❌ CenterFace model conversion failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert MobileFaceNet ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time (generate): 19.456s\n",
      "\n",
      "✅ Conversion completed successfully.\n",
      "✅ MobileFaceNet model conversion completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Convert MobileFaceNet model\n",
    "print(\"Converting MobileFaceNet ONNX model...\")\n",
    "mobilefacenet_success = run_stedgeai_conversion(\n",
    "    mobilefacenet_model, \n",
    "    'face_recognition',\n",
    "    target=\"stm32n6\",\n",
    "    input_data_type=\"float32\",\n",
    "    neural_art_config = \"face_recognition_config.json\",\n",
    "    profile_config = \"mobilefacenet\"\n",
    ")\n",
    "\n",
    "if mobilefacenet_success:\n",
    "    print(\"✅ MobileFaceNet model conversion completed successfully\")\n",
    "else:\n",
    "    print(\"❌ MobileFaceNet model conversion failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CONVERSION SUMMARY\n",
      "==================================================\n",
      "CenterFace TFLite → STM32: ✅ Success\n",
      "MobileFaceNet ONNX → STM32: ✅ Success\n",
      "\n",
      "Generated files are organized in the ./stm32_output directory\n",
      "\n",
      "Next steps:\n",
      "1. Review the generated network.c and network.h files\n",
      "2. Integrate the models into your STM32 project\n",
      "3. Configure memory pools based on the .mpool files\n",
      "4. Test the models on your target STM32 hardware\n",
      "\n",
      "Generated files:\n",
      "  mobilefacenet_int8_faces_OE_3_2_0.onnx\n",
      "  LICENSE.txt\n",
      "  face_recognition_c_info.json\n",
      "  face_recognition.h\n",
      "  centerface_OE_3_2_0_Q.json\n",
      "  face_recognition.c\n",
      "  face_recognition_atonbuf.xSPI2.raw\n",
      "  face_detection.c\n",
      "  centerface_OE_3_2_0.onnx\n",
      "  face_recognition_generate_report.txt\n",
      "  face_detection_c_info.json\n",
      "  face_detection.h\n",
      "  face_detection_atonbuf.xSPI2.raw\n",
      "  mobilefacenet_int8_faces_OE_3_2_0_Q.json\n",
      "  face_detection_generate_report.txt\n",
      "  face_recognition_ecblobs.h\n",
      "  face_detection_ecblobs.h\n",
      "  code/face_recognition.h\n",
      "  code/face_recognition.c\n",
      "  code/face_detection.c\n",
      "  code/face_detection.h\n",
      "  code/face_recognition_ecblobs.h\n",
      "  code/face_detection_ecblobs.h\n",
      "  binaries/face_detection_data.bin\n",
      "  binaries/face_recognition_data.bin\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CONVERSION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"CenterFace TFLite → STM32: {'✅ Success' if centerface_success else '❌ Failed'}\")\n",
    "print(f\"MobileFaceNet ONNX → STM32: {'✅ Success' if mobilefacenet_success else '❌ Failed'}\")\n",
    "\n",
    "print(\"\\nGenerated files are organized in the ./stm32_output directory\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Review the generated network.c and network.h files\")\n",
    "print(\"2. Integrate the models into your STM32 project\")\n",
    "print(\"3. Configure memory pools based on the .mpool files\")\n",
    "print(\"4. Test the models on your target STM32 hardware\")\n",
    "\n",
    "# List generated files\n",
    "print(\"\\nGenerated files:\")\n",
    "for item in output_dir.rglob('*'):\n",
    "    if item.is_file():\n",
    "        print(f\"  {item.relative_to(output_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing and File Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def organize_output_files(model_name):\n",
    "    st_ai_output = Path('converted_models')\n",
    "\n",
    "    if st_ai_output.exists():\n",
    "        code_dir = Path(st_ai_output,'code')\n",
    "        binaries_dir = Path(st_ai_output, 'binaries')\n",
    "        code_dir.mkdir(exist_ok=True)\n",
    "        binaries_dir.mkdir(exist_ok=True)\n",
    "        # Copy header and C files\n",
    "        patterns = [f'{model_name}*.c', f'{model_name}*.h', f'{model_name}*_ecblobs.h', 'f{model_name}*_data.h']\n",
    "\n",
    "        for pattern in patterns:\n",
    "            for src_file in st_ai_output.glob(pattern):\n",
    "                dst_file = code_dir / src_file.name\n",
    "                shutil.move(src_file, dst_file)\n",
    "                print(f\"moved {src_file.name} to {dst_file}\")\n",
    "\n",
    "        # Handle raw binary file\n",
    "        binary_files = list(st_ai_output.glob(f'{model_name}*.raw'))\n",
    "        if binary_files:\n",
    "            \n",
    "            binary_file = binary_files[0]\n",
    "            print(binary_file)\n",
    "            bin_output = binaries_dir / f'{model_name}_data.bin'\n",
    "            print(bin_output)\n",
    "            hex_output = binaries_dir / f'{model_name}_data.hex'\n",
    "            print(hex_output)\n",
    "            shutil.copy(binary_file, bin_output)\n",
    "            print(f\"Copied binary: {binary_file.name} to {bin_output}\")\n",
    "\n",
    "            # Set address\n",
    "            address_map = {\n",
    "                'face_detection': '0x71000000',\n",
    "                'face_recognition': '0x72000000',\n",
    "            }\n",
    "            address = address_map.get(model_name, '0x70380000')\n",
    "\n",
    "            try:\n",
    "                subprocess.run([\n",
    "                    'arm-none-eabi-objcopy', '-I', 'binary', str(bin_output),\n",
    "                    '--change-addresses', address, '-O', 'ihex', str(hex_output)\n",
    "                ], check=True)\n",
    "                print(f\"Generated HEX file: {hex_output} at address {address}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Warning: HEX generation failed: {e}\")\n",
    "    else:\n",
    "        print(\"Warning: st_ai_output directory not found\")\n",
    "\n",
    "    return st_ai_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved face_detection.c to converted_models/code/face_detection.c\n",
      "moved face_detection.h to converted_models/code/face_detection.h\n",
      "moved face_detection_ecblobs.h to converted_models/code/face_detection_ecblobs.h\n",
      "converted_models/face_detection_atonbuf.xSPI2.raw\n",
      "converted_models/binaries/face_detection_data.bin\n",
      "converted_models/binaries/face_detection_data.hex\n",
      "Copied binary: face_detection_atonbuf.xSPI2.raw to converted_models/binaries/face_detection_data.bin\n",
      "Generated HEX file: converted_models/binaries/face_detection_data.hex at address 0x71000000\n",
      "CenterFace files organized in: converted_models\n"
     ]
    }
   ],
   "source": [
    "if centerface_success:\n",
    "    centerface_dir = organize_output_files('face_detection')\n",
    "    print(f\"CenterFace files organized in: {centerface_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved face_recognition.c to converted_models/code/face_recognition.c\n",
      "moved face_recognition.h to converted_models/code/face_recognition.h\n",
      "moved face_recognition_ecblobs.h to converted_models/code/face_recognition_ecblobs.h\n",
      "converted_models/face_recognition_atonbuf.xSPI2.raw\n",
      "converted_models/binaries/face_recognition_data.bin\n",
      "converted_models/binaries/face_recognition_data.hex\n",
      "Copied binary: face_recognition_atonbuf.xSPI2.raw to converted_models/binaries/face_recognition_data.bin\n",
      "Generated HEX file: converted_models/binaries/face_recognition_data.hex at address 0x72000000\n",
      "MobileFaceNet files organized in: converted_models\n"
     ]
    }
   ],
   "source": [
    "if mobilefacenet_success:\n",
    "    mobilefacenet_dir = organize_output_files('face_recognition')\n",
    "    print(f\"MobileFaceNet files organized in: {mobilefacenet_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
